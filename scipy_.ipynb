{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3yV9boXcOh-",
        "outputId": "eca4ecb5-878d-4bb3-b49a-38fb69eb2e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "\n",
        "# List functions in the main scipy module\n",
        "print(\"Functions in scipy module:\")\n",
        "print(dir(scipy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaL8jttNcwP6",
        "outputId": "91aff695-68e9-42b2-bdfe-b7e1d23bab41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functions in scipy module:\n",
            "['LowLevelCallable', '__numpy_version__', '__version__', 'cluster', 'datasets', 'fft', 'fftpack', 'integrate', 'interpolate', 'io', 'linalg', 'misc', 'ndimage', 'odr', 'optimize', 'show_config', 'signal', 'sparse', 'spatial', 'special', 'stats', 'test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List functions in a specific sub-package (e.g., linalg)\n",
        "from scipy import linalg\n",
        "print(\"\\nFunctions in scipy.linalg sub-package:\")\n",
        "print(dir(linalg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWXywRs8cyK2",
        "outputId": "fec615ab-6de6-4cd3-b96f-95724c970855"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Functions in scipy.linalg sub-package:\n",
            "['LinAlgError', 'LinAlgWarning', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_basic', '_cythonized_array_utils', '_decomp', '_decomp_cholesky', '_decomp_cossin', '_decomp_ldl', '_decomp_lu', '_decomp_polar', '_decomp_qr', '_decomp_qz', '_decomp_schur', '_decomp_svd', '_decomp_update', '_expm_frechet', '_fblas', '_flapack', '_flinalg', '_flinalg_py', '_matfuncs', '_matfuncs_expm', '_matfuncs_sqrtm', '_matfuncs_sqrtm_triu', '_misc', '_procrustes', '_sketches', '_solve_toeplitz', '_solvers', '_special_matrices', 'bandwidth', 'basic', 'blas', 'block_diag', 'cdf2rdf', 'cho_factor', 'cho_solve', 'cho_solve_banded', 'cholesky', 'cholesky_banded', 'circulant', 'clarkson_woodruff_transform', 'companion', 'convolution_matrix', 'coshm', 'cosm', 'cossin', 'cython_blas', 'cython_lapack', 'decomp', 'decomp_cholesky', 'decomp_lu', 'decomp_qr', 'decomp_schur', 'decomp_svd', 'det', 'dft', 'diagsvd', 'eig', 'eig_banded', 'eigh', 'eigh_tridiagonal', 'eigvals', 'eigvals_banded', 'eigvalsh', 'eigvalsh_tridiagonal', 'expm', 'expm_cond', 'expm_frechet', 'fiedler', 'fiedler_companion', 'find_best_blas_type', 'flinalg', 'fractional_matrix_power', 'funm', 'get_blas_funcs', 'get_lapack_funcs', 'hadamard', 'hankel', 'helmert', 'hessenberg', 'hilbert', 'inv', 'invhilbert', 'invpascal', 'ishermitian', 'issymmetric', 'khatri_rao', 'kron', 'lapack', 'ldl', 'leslie', 'logm', 'lstsq', 'lu', 'lu_factor', 'lu_solve', 'matfuncs', 'matmul_toeplitz', 'matrix_balance', 'misc', 'norm', 'null_space', 'ordqz', 'orth', 'orthogonal_procrustes', 'pascal', 'pinv', 'pinvh', 'polar', 'qr', 'qr_delete', 'qr_insert', 'qr_multiply', 'qr_update', 'qz', 'rq', 'rsf2csf', 'schur', 'signm', 'sinhm', 'sinm', 'solve', 'solve_banded', 'solve_circulant', 'solve_continuous_are', 'solve_continuous_lyapunov', 'solve_discrete_are', 'solve_discrete_lyapunov', 'solve_lyapunov', 'solve_sylvester', 'solve_toeplitz', 'solve_triangular', 'solveh_banded', 'special_matrices', 'sqrtm', 'subspace_angles', 'svd', 'svdvals', 'tanhm', 'tanm', 'test', 'toeplitz', 'tri', 'tril', 'triu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Algebra\n"
      ],
      "metadata": {
        "id": "hiSLYou4dYMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Representation: In data science, data is often represented in the form of matrices and vectors. Each row of a matrix can represent an observation, while each column can represent a specific feature or variable. Linear algebra provides the necessary framework for organizing and representing data in a structured and concise manner.\n",
        "\n",
        "2. Linear Transformations: Many data transformations, such as rotation, scaling, and projection, can be represented as linear transformations. Linear algebra allows data scientists to apply these transformations efficiently using matrix operations, which is especially useful in tasks like feature engineering and dimensionality reduction.\n",
        "\n",
        "3. Solving Linear Systems: Data science often involves solving systems of linear equations to model relationships between variables or predict outcomes. Linear algebra provides techniques like matrix inversion and solving linear systems, which are used in various data analysis and machine learning algorithms.\n",
        "\n",
        "4. Eigenvalues and Eigenvectors: Eigenvalues and eigenvectors are crucial concepts in linear algebra used to understand the underlying structure and variance of data. They are used in techniques like principal component analysis (PCA) for dimensionality reduction and feature extraction.\n",
        "\n",
        "5. Optimization: Data scientists often encounter optimization problems when training machine learning models or finding the best solution to a particular task. Linear algebra techniques, such as gradient descent, help in optimizing parameters to achieve the best model performance.\n",
        "\n",
        "6. Singular Value Decomposition (SVD): SVD is a powerful linear algebra tool used for data compression, noise reduction, and latent semantic analysis in natural language processing and recommendation systems.\n",
        "\n",
        "7. Image and Signal Processing: Linear algebra is extensively used in image and signal processing tasks, such as image compression, denoising, and image recognition. Techniques like the discrete Fourier transform (DFT) are based on linear algebra principles.\n",
        "\n",
        "8. Data Manipulation and Linear Operations: Many data manipulations, such as data filtering, smoothing, and interpolation, can be performed using linear algebra operations like convolution and matrix multiplication.\n",
        "\n",
        "9. Machine Learning Algorithms: Linear algebra forms the backbone of various machine learning algorithms, including linear regression, support vector machines (SVMs), and neural networks. It allows for efficient computation and model training.\n",
        "\n",
        "10. Numerical Stability: Linear algebra plays a vital role in ensuring numerical stability and accuracy in data computations. Techniques like LU decomposition and QR decomposition are used to enhance the numerical stability of algorithms."
      ],
      "metadata": {
        "id": "8eBkrniHf9K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "# Example matrices\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "# Matrix addition\n",
        "C = A + B\n",
        "print(\"Matrix Addition:\")\n",
        "print(C)\n",
        "\n",
        "# Matrix subtraction\n",
        "D = A - B\n",
        "print(\"Matrix Subtraction:\")\n",
        "print(D)\n",
        "\n",
        "# Scalar multiplication\n",
        "scalar = 2\n",
        "E = scalar * A\n",
        "print(\"Scalar Multiplication:\")\n",
        "print(E)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjjd6btrhBP4",
        "outputId": "1e61078b-44e2-4dc8-b3c1-5ac060d364cf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Addition:\n",
            "[[ 6  8]\n",
            " [10 12]]\n",
            "Matrix Subtraction:\n",
            "[[-4 -4]\n",
            " [-4 -4]]\n",
            "Scalar Multiplication:\n",
            "[[2 4]\n",
            " [6 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Solving Linear Systems\n",
        "\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "# Example matrix and vector\n",
        "A = np.array([[2, 1], [3, 4]])\n",
        "b = np.array([5, 6])\n",
        "\n",
        "# Solve the linear system Ax = b\n",
        "x = linalg.solve(A, b)\n",
        "print(\"Solution x:\")\n",
        "print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_bKTVFphG_A",
        "outputId": "52127bc2-e961-4c2d-ef0c-a55e6e21d741"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution x:\n",
            "[ 2.8 -0.6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Solving a linear system Ax = b\n",
        "b = np.array([1, 2])\n",
        "x = linalg.solve(A, b)\n",
        "print(\"Solution x:\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvMZ1g2IhSMM",
        "outputId": "aa832b3c-1397-42ae-e15b-033af7a05509"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution x: [0.4 0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "# Example matrix\n",
        "A = np.array([[2, 1], [3, 4]])\n",
        "\n",
        "# Computing the determinant of a matrix\n",
        "det_A = linalg.det(A)\n",
        "print(\"Determinant of A:\", det_A)\n",
        "\n",
        "# Finding the eigenvalues and eigenvectors of a matrix\n",
        "eigenvalues, eigenvectors = linalg.eig(A)\n",
        "print(\"Eigenvalues:\", eigenvalues)\n",
        "print(\"Eigenvectors:\")\n",
        "for i in range(len(eigenvectors)):\n",
        "    print(\"Eigenvalue:\", eigenvalues[i])\n",
        "    print(\"Eigenvector:\", eigenvectors[:, i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y_SY_Esc3Gj",
        "outputId": "68df1ccf-3cb1-4c37-ea8b-a21515f83a2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Determinant of A: 5.0\n",
            "Solution x: [0.4 0.2]\n",
            "Eigenvalues: [1.+0.j 5.+0.j]\n",
            "Eigenvectors:\n",
            "Eigenvalue: (1+0j)\n",
            "Eigenvector: [-0.70710678  0.70710678]\n",
            "Eigenvalue: (5+0j)\n",
            "Eigenvector: [-0.31622777 -0.9486833 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix inversion is a fundamental operation in linear algebra that involves finding the \"inverse\" of a square matrix. Given a square matrix A, its inverse, denoted as A^-1, is a new matrix that, when multiplied with A, yields the identity matrix (I). The identity matrix is a special square matrix with ones on the main diagonal and zeros elsewhere."
      ],
      "metadata": {
        "id": "qnNW_8kagWo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Matrix Inversion (scipy.linalg.inv):\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "# Example matrix\n",
        "A = np.array([[2, 1], [3, 4]])\n",
        "print(A)\n",
        "\n",
        "# Matrix inversion\n",
        "A_inv = linalg.inv(A)\n",
        "print(\"Inverse of A:\")\n",
        "print(A_inv)\n",
        "\n",
        "# Verify: A * A_inv should be the identity matrix\n",
        "identity_matrix = np.dot(A, A_inv)\n",
        "print(\"A * A_inv:\")\n",
        "print(identity_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viNZ696Odd-W",
        "outputId": "5922ac3e-907f-4ed7-bb99-4d8da5b84568"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 1]\n",
            " [3 4]]\n",
            "Inverse of A:\n",
            "[[ 0.8 -0.2]\n",
            " [-0.6  0.4]]\n",
            "A * A_inv:\n",
            "[[1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QR decomposition is a matrix factorization technique in linear algebra. It decomposes a matrix A into the product of an orthogonal matrix Q and an upper triangular matrix R. This factorization is widely used in various numerical algorithms, including solving linear systems, least squares problems, and eigenvalue computations"
      ],
      "metadata": {
        "id": "sHN8I0gqiEVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "# Example matrix\n",
        "A = np.array([[2, 1], [3, 4], [1, 2]])\n",
        "\n",
        "# Perform QR decomposition\n",
        "Q, R = linalg.qr(A)\n",
        "\n",
        "print(\"Orthogonal matrix Q:\")\n",
        "print(Q)\n",
        "print(\"Upper triangular matrix R:\")\n",
        "print(R)\n",
        "\n",
        "# Verify: Reconstruct A from Q and R\n",
        "A_reconstructed = np.dot(Q, R)\n",
        "print(\"A reconstructed from Q and R:\")\n",
        "print(A_reconstructed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_N22DmjhtqH",
        "outputId": "88866f2a-721f-45d1-debd-05012694d16a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orthogonal matrix Q:\n",
            "[[-0.53452248  0.78039897  0.32444284]\n",
            " [-0.80178373 -0.34684399 -0.48666426]\n",
            " [-0.26726124 -0.52026598  0.81110711]]\n",
            "Upper triangular matrix R:\n",
            "[[-3.74165739 -4.27617987]\n",
            " [ 0.         -1.64750894]\n",
            " [ 0.          0.        ]]\n",
            "A reconstructed from Q and R:\n",
            "[[2. 1.]\n",
            " [3. 4.]\n",
            " [1. 2.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LU decomposition, also known as LU factorization, is a method used to factorize a square matrix A into the product of two triangular matrices: a lower triangular matrix L and an upper triangular matrix U. It is widely used in numerical linear algebra and plays a crucial role in solving systems of linear equations and matrix inversion."
      ],
      "metadata": {
        "id": "LK62fIkjgabj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LU Decomposition (scipy.linalg.lu):\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "# Example matrix\n",
        "A = np.array([[2, 1], [3, 4]])\n",
        "\n",
        "# LU decomposition\n",
        "P, L, U = linalg.lu(A)\n",
        "print(\"Permutation matrix P:\")\n",
        "print(P)\n",
        "print(\"Lower triangular matrix L:\")\n",
        "print(L)\n",
        "print(\"Upper triangular matrix U:\")\n",
        "print(U)\n",
        "\n",
        "# Verify: Reconstruct A from LU decomposition\n",
        "A_reconstructed = P @ L @ U\n",
        "print(\"A reconstructed from LU decomposition:\")\n",
        "print(A_reconstructed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0QV7zI8duCm",
        "outputId": "61d2a86b-cd1c-4d95-be09-4437145e33a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Permutation matrix P:\n",
            "[[0. 1.]\n",
            " [1. 0.]]\n",
            "Lower triangular matrix L:\n",
            "[[1.         0.        ]\n",
            " [0.66666667 1.        ]]\n",
            "Upper triangular matrix U:\n",
            "[[ 3.          4.        ]\n",
            " [ 0.         -1.66666667]]\n",
            "A reconstructed from LU decomposition:\n",
            "[[2. 1.]\n",
            " [3. 4.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix norms are mathematical measures used to determine the \"size\" or magnitude of a matrix. Similar to vector norms, which quantify the \"length\" of a vector, matrix norms provide a way to assess the \"size\" of a matrix in various ways. Different matrix norms are defined based on different properties and have various applications in linear algebra, numerical analysis, and other fields."
      ],
      "metadata": {
        "id": "hxw8cY0jgeFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Norms (scipy.linalg.norm):\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "# Example matrix\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Matrix norms\n",
        "frobenius_norm = linalg.norm(A, ord='fro')\n",
        "print(\"Frobenius norm of A:\", frobenius_norm)\n",
        "\n",
        "# Other norms\n",
        "# L1 norm (max column sum)\n",
        "l1_norm = linalg.norm(A, ord=1)\n",
        "print(\"L1 norm of A:\", l1_norm)\n",
        "\n",
        "# L2 norm (max singular value)\n",
        "l2_norm = linalg.norm(A, ord=2)\n",
        "print(\"L2 norm of A:\", l2_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSD2Mv62d97I",
        "outputId": "e6d00462-c2b9-4500-9a9c-76a2d326733e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frobenius norm of A: 5.477225575051661\n",
            "L1 norm of A: 6.0\n",
            "L2 norm of A: 5.464985704219043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization"
      ],
      "metadata": {
        "id": "oUjnUgRWi9rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the Minimum of a Function\n",
        "\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize_scalar\n",
        "\n",
        "# Define the function to minimize\n",
        "def f(x):\n",
        "    return x**2 + 5*x + 6\n",
        "\n",
        "# Use minimize_scalar to find the minimum of the function\n",
        "result = minimize_scalar(f)\n",
        "\n",
        "# Extract the minimum value and the corresponding argument\n",
        "min_value = result.fun\n",
        "min_arg = result.x\n",
        "\n",
        "print(\"Minimum value:\", min_value)\n",
        "print(\"Argument for minimum value:\", min_arg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpML_AyFeLy1",
        "outputId": "d462a389-e7a8-4810-cd23-d462e6efbfe6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value: -0.25\n",
            "Argument for minimum value: -2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizing Parameters for Machine Learning Models\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Example data for linear regression\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([3, 5, 7, 9, 11])\n",
        "\n",
        "# Define the loss function (Mean Squared Error for linear regression)\n",
        "def loss_function(params):\n",
        "    predicted_y = params[0] * X + params[1]\n",
        "    return np.mean((predicted_y - y)**2)\n",
        "\n",
        "# Use minimize to find the best parameters for linear regression\n",
        "initial_guess = [1, 0]  # Initial guess for parameters\n",
        "result = minimize(loss_function, initial_guess)\n",
        "\n",
        "# Extract the optimized parameters\n",
        "optimal_params = result.x\n",
        "\n",
        "print(\"Optimized parameters:\", optimal_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92FtOXbnjCon",
        "outputId": "91063deb-9f64-4965-8b1f-8a677a9abd7a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized parameters: [1.99999968 1.00000125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Optimization\n",
        "import numpy as np\n",
        "from scipy.optimize import differential_evolution\n",
        "\n",
        "# Define the function to minimize (Rosenbrock function)\n",
        "def rosenbrock(x):\n",
        "    return (1 - x[0])**2 + 100 * (x[1] - x[0]**2)**2\n",
        "\n",
        "# Use differential_evolution for global optimization\n",
        "result = differential_evolution(rosenbrock, [(-2, 2), (-2, 2)])\n",
        "\n",
        "# Extract the global minimum value and arguments\n",
        "global_min_value = result.fun\n",
        "global_min_args = result.x\n",
        "\n",
        "print(\"Global minimum value:\", global_min_value)\n",
        "print(\"Arguments for global minimum value:\", global_min_args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMpye9s2jNUJ",
        "outputId": "8292dc2b-78d2-4276-ae0d-d855010215d8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global minimum value: 0.0\n",
            "Arguments for global minimum value: [1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lkJRexgBjc_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}